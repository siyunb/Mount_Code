{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapNode\n",
    "\n",
    "If you want to iterate over a list of inputs, but need to feed all iterated outputs afterward as one input (an array) to the next node, you need to use a **``MapNode``**. A ``MapNode`` is quite similar to a normal ``Node``, but it can take a list of inputs and operate over each input separately, ultimately returning a list of outputs.\n",
    "\n",
    "Imagine that you have a list of items (let's say files) and you want to execute the same node on them (for example some smoothing or masking). Some nodes accept multiple files and do exactly the same thing on them, but some don't (they expect only one file). `MapNode` can solve this problem. Imagine you have the following workflow:\n",
    "\n",
    "<img src=\"../static/images/mapnode.png\"  width=\"325\">\n",
    "\n",
    "Node `A` outputs a list of files, but node `B` accepts only one file. Additionally, `C` expects a list of files. What you would like is to run `B` for every file in the output of `A` and collect the results as a list and feed it to `C`. Something like this:\n",
    "\n",
    "```python\n",
    "from nipype import Node, MapNode, Workflow\n",
    "a = Node(interface=A(), name=\"a\")\n",
    "b = MapNode(interface=B(), name=\"b\", iterfield=['in_file'])\n",
    "c = Node(interface=C(), name=\"c\")\n",
    "\n",
    "my_workflow = Workflow(name=\"my_workflow\")\n",
    "my_workflow.connect([(a,b,[('out_files','in_file')]),\n",
    "                     (b,c,[('out_file','in_files')])\n",
    "                     ])\n",
    "```\n",
    "\n",
    "Let's demonstrate this with a simple function interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Function\n",
    "def square_func(x):\n",
    "    return x ** 2\n",
    "square = Function([\"x\"], [\"f_x\"], square_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this function just takes a numeric input and returns its squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square.run(x=2).outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to square a list of numbers? We could set an iterable and just split up the workflow in multiple sub-workflows. But say we were making a simple workflow that squared a list of numbers and then summed them. The sum node would expect a list, but using an iterable would make a bunch of sum nodes, and each would get one number from the list. The solution here is to use a `MapNode`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `iterfield`\n",
    "\n",
    "The `MapNode` constructor has a field called `iterfield`, which tells it what inputs should be expecting a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import MapNode\n",
    "square_node = MapNode(square, name=\"square\", iterfield=[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211103-17:05:56,187 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"square\" in \"/tmp/tmpq6s8od3w/square\".\n",
      "211103-17:05:56,190 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_square0\" in \"/tmp/tmpq6s8od3w/square/mapflow/_square0\".\n",
      "211103-17:05:56,192 nipype.workflow INFO:\n",
      "\t [Node] Running \"_square0\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:05:56,195 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_square0\".\n",
      "211103-17:05:56,196 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_square1\" in \"/tmp/tmpq6s8od3w/square/mapflow/_square1\".\n",
      "211103-17:05:56,198 nipype.workflow INFO:\n",
      "\t [Node] Running \"_square1\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:05:56,200 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_square1\".\n",
      "211103-17:05:56,202 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_square2\" in \"/tmp/tmpq6s8od3w/square/mapflow/_square2\".\n",
      "211103-17:05:56,204 nipype.workflow INFO:\n",
      "\t [Node] Running \"_square2\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:05:56,206 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_square2\".\n",
      "211103-17:05:56,207 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_square3\" in \"/tmp/tmpq6s8od3w/square/mapflow/_square3\".\n",
      "211103-17:05:56,209 nipype.workflow INFO:\n",
      "\t [Node] Running \"_square3\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:05:56,211 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_square3\".\n",
      "211103-17:05:56,212 nipype.workflow INFO:\n",
      "\t [Node] Finished \"square\".\n"
     ]
    }
   ],
   "source": [
    "square_node.inputs.x = [0, 1, 2, 3]\n",
    "res = square_node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `iterfield` can take a list of names, you can operate over multiple sets of data, as long as they're the same length. The values in each list will be paired; it does not compute a combinatoric product of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_func(x, y):\n",
    "    return x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211103-17:08:56,984 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"power\" in \"/tmp/tmp_6b6gik8/power\".\n",
      "211103-17:08:56,988 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power0\" in \"/tmp/tmp_6b6gik8/power/mapflow/_power0\".\n",
      "211103-17:08:56,990 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power0\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:08:56,992 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power0\".\n",
      "211103-17:08:56,994 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power1\" in \"/tmp/tmp_6b6gik8/power/mapflow/_power1\".\n",
      "211103-17:08:56,995 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power1\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:08:56,998 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power1\".\n",
      "211103-17:08:56,999 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power2\" in \"/tmp/tmp_6b6gik8/power/mapflow/_power2\".\n",
      "211103-17:08:57,1 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power2\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:08:57,3 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power2\".\n",
      "211103-17:08:57,4 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power3\" in \"/tmp/tmp_6b6gik8/power/mapflow/_power3\".\n",
      "211103-17:08:57,6 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power3\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:08:57,8 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power3\".\n",
      "211103-17:08:57,10 nipype.workflow INFO:\n",
      "\t [Node] Finished \"power\".\n"
     ]
    }
   ],
   "source": [
    "power = Function([\"x\", \"y\"], [\"f_xy\"], power_func)\n",
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\", \"y\"])\n",
    "power_node.inputs.x = [0, 1, 2, 3]\n",
    "power_node.inputs.y = [0, 1, 2, 3]\n",
    "res = power_node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 4, 27]\n"
     ]
    }
   ],
   "source": [
    "print(res.outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not every input needs to be an iterfield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211103-17:09:24,966 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"power\" in \"/tmp/tmp5i1xfcz3/power\".\n",
      "211103-17:09:24,968 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power0\" in \"/tmp/tmp5i1xfcz3/power/mapflow/_power0\".\n",
      "211103-17:09:24,971 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power0\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:09:24,974 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power0\".\n",
      "211103-17:09:24,976 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power1\" in \"/tmp/tmp5i1xfcz3/power/mapflow/_power1\".\n",
      "211103-17:09:24,977 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power1\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:09:24,980 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power1\".\n",
      "211103-17:09:24,982 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power2\" in \"/tmp/tmp5i1xfcz3/power/mapflow/_power2\".\n",
      "211103-17:09:24,985 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power2\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:09:24,987 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power2\".\n",
      "211103-17:09:24,989 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_power3\" in \"/tmp/tmp5i1xfcz3/power/mapflow/_power3\".\n",
      "211103-17:09:24,991 nipype.workflow INFO:\n",
      "\t [Node] Running \"_power3\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211103-17:09:24,993 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_power3\".\n",
      "211103-17:09:24,995 nipype.workflow INFO:\n",
      "\t [Node] Finished \"power\".\n"
     ]
    }
   ],
   "source": [
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\"])\n",
    "power_node.inputs.x = [0, 1, 2, 3]\n",
    "power_node.inputs.y = 3\n",
    "res = power_node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 8, 27]\n"
     ]
    }
   ],
   "source": [
    "print(res.outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of `iterables`, each underlying `MapNode` execution can happen in **parallel**. Hopefully, you see how these tools allow you to write flexible, reusable workflows that will help you process large amounts of data efficiently and reproducibly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more advanced applications it is useful to be able to iterate over items of nested lists (for example ``[[1,2],[3,4]]``). MapNode allows you to do this with the \"nested=True\" parameter. Outputs will preserve the same nested structure as the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is this important?\n",
    "\n",
    "Let's consider we have multiple functional images (A) and each of them should be motioned corrected (B1, B2, B3,..). But afterward, we want to put them all together into a GLM, i.e. the input for the GLM should be an array of [B1, B2, B3, ...]. [Iterables](basic_iteration.ipynb) can't do that. They would split up the pipeline. Therefore, we need **MapNodes**.\n",
    "\n",
    "<img src=\"../static/images/mapnode.png\"  width=\"300\">\n",
    "\n",
    "Let's look at a simple example, where we want to motion correct two functional images. For this we need two nodes:\n",
    " - Gunzip, to unzip the files (plural)\n",
    " - Realign, to do the motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.spm import Realign\n",
    "from nipype import Node, MapNode, Workflow\n",
    "\n",
    "# Here we specify a list of files (for this tutorial, we just add the same file twice)\n",
    "files = ['/home/neuro/Data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz',\n",
    "         '/home/neuro/Data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz']\n",
    "\n",
    "realign = Node(Realign(register_to_mean=True),\n",
    "               name='motion_correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to specify the input for the **Gunzip** node with a simple **Node**, we get the following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TraitError: The 'in_file' trait of a GunzipInputSpec instance must be a pathlike object or string representing an existing file, but a value of \"['/home/neuro/Data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz', '/home/neuro/Data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz']\" <class 'str'> was specified.\n"
     ]
    }
   ],
   "source": [
    "gunzip = Node(Gunzip(), name='gunzip',)\n",
    "try:\n",
    "    gunzip.inputs.in_file = files\n",
    "except(Exception) as err:\n",
    "    if \"TraitError\" in str(err.__class__):\n",
    "        print(\"TraitError:\", err)\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "TraitError: The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz', '/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz'] <class 'list'> was specified.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we do it with a **MapNode**, it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip = MapNode(Gunzip(), name='gunzip',\n",
    "                 iterfield=['in_file'])\n",
    "gunzip.inputs.in_file = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just have to create a workflow, connect the nodes and we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211103-17:16:59,838 nipype.workflow INFO:\n",
      "\t Workflow realign_with_spm settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "211103-17:16:59,862 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "211103-17:16:59,864 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 7.43/7.43, Free processors: 4/4.\n",
      "211103-17:17:01,866 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 7.43/7.43, Free processors: 4/4.\n",
      "211103-17:17:01,956 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzip0\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/realign_with_spm/gunzip/mapflow/_gunzip0\".\n",
      "211103-17:17:01,958 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzip1\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/realign_with_spm/gunzip/mapflow/_gunzip1\".\n",
      "211103-17:17:01,992 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzip0\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "211103-17:17:01,994 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzip1\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "211103-17:17:02,660 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzip0\".\n",
      "211103-17:17:02,664 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzip1\".\n",
      "211103-17:17:03,868 nipype.workflow INFO:\n",
      "\t [Job 2] Completed (_gunzip0).\n",
      "211103-17:17:03,870 nipype.workflow INFO:\n",
      "\t [Job 3] Completed (_gunzip1).\n",
      "211103-17:17:03,871 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 7.43/7.43, Free processors: 4/4.\n",
      "211103-17:17:03,959 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"realign_with_spm.gunzip\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/realign_with_spm/gunzip\".\n",
      "211103-17:17:03,986 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzip0\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/realign_with_spm/gunzip/mapflow/_gunzip0\".\n",
      "211103-17:17:03,993 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_gunzip0\" - collecting precomputed outputs\n",
      "211103-17:17:03,994 nipype.workflow INFO:\n",
      "\t [Node] \"_gunzip0\" found cached.\n",
      "211103-17:17:03,996 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzip1\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/realign_with_spm/gunzip/mapflow/_gunzip1\".\n",
      "211103-17:17:04,3 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_gunzip1\" - collecting precomputed outputs\n",
      "211103-17:17:04,4 nipype.workflow INFO:\n",
      "\t [Node] \"_gunzip1\" found cached.\n",
      "211103-17:17:04,20 nipype.workflow INFO:\n",
      "\t [Node] Finished \"realign_with_spm.gunzip\".\n",
      "211103-17:17:05,870 nipype.workflow INFO:\n",
      "\t [Job 0] Completed (realign_with_spm.gunzip).\n",
      "211103-17:17:05,872 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 7.43/7.43, Free processors: 4/4.\n",
      "211103-17:17:05,929 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"realign_with_spm.motion_correction\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/realign_with_spm/motion_correction\".\n",
      "211103-17:17:06,793 nipype.workflow INFO:\n",
      "\t [Node] Running \"motion_correction\" (\"nipype.interfaces.spm.preprocess.Realign\")\n",
      "211103-17:17:07,873 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 7.23/7.43, Free processors: 3/4.\n",
      "                     Currently running:\n",
      "                       * realign_with_spm.motion_correction\n",
      "211103-17:18:24,353 nipype.workflow INFO:\n",
      "\t [Node] Finished \"realign_with_spm.motion_correction\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211103-17:18:25,939 nipype.workflow INFO:\n",
      "\t [Job 1] Completed (realign_with_spm.motion_correction).\n",
      "211103-17:18:25,946 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 0 jobs ready. Free memory (GB): 7.43/7.43, Free processors: 4/4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fd89e4e86a0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcflow = Workflow(name='realign_with_spm')\n",
    "mcflow.connect(gunzip, 'out_file', realign, 'in_files')\n",
    "mcflow.base_dir = '/home/neuro/Result/Nipype_tutorial/working_dir'\n",
    "mcflow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a workflow to calculate a sum of factorials of numbers from a range between $n_{min}$ and $n_{max}$, i.e.:\n",
    "\n",
    "$$\\sum _{k=n_{min}}^{n_{max}} k! = 0! + 1! +2! + 3! + \\cdots$$ \n",
    "\n",
    "if $n_{min}=0$ and $n_{max}=3$\n",
    "$$\\sum _{k=0}^{3} k! = 0! + 1! +2! + 3!  =  1 + 1 + 2 + 6 = 10$$\n",
    "\n",
    "Use ``Node`` for a function that creates a list of integers and a function that sums everything at the end. Use ``MapNode`` to calculate factorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#write your solution here\n",
    "def factorial(n):\n",
    "    multiply_result = 1\n",
    "    if n == 0:\n",
    "        return multiply_result\n",
    "    else:\n",
    "        while n>0:\n",
    "            multiply_result *= n\n",
    "            n -= 1\n",
    "        return multiply_result\n",
    "\n",
    "def sum_func(fac_list):\n",
    "    return sum(fac_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211104-13:40:56,363 nipype.workflow INFO:\n",
      "\t Workflow exer_wf settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "211104-13:40:56,379 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "211104-13:40:56,380 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"exer_wf.exercise1\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/exercise1\".\n",
      "211104-13:40:56,384 nipype.workflow INFO:\n",
      "\t [Node] \"exer_wf.exercise1\" found cached.\n",
      "211104-13:40:56,385 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"exer_wf.sum\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/sum\".\n",
      "211104-13:40:56,388 nipype.workflow INFO:\n",
      "\t [Node] Cached \"exer_wf.sum\" - collecting precomputed outputs\n",
      "211104-13:40:56,389 nipype.workflow INFO:\n",
      "\t [Node] \"exer_wf.sum\" found cached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "sum_result = 10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ex_wf.run().nodes())[1].result.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211104-13:40:03,49 nipype.workflow INFO:\n",
      "\t Workflow exer_wf settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "211104-13:40:03,77 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "211104-13:40:03,78 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"exer_wf.exercise1\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/exercise1\".\n",
      "211104-13:40:03,111 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_exercise10\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/exercise1/mapflow/_exercise10\".\n",
      "211104-13:40:03,139 nipype.workflow INFO:\n",
      "\t [Node] Running \"_exercise10\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211104-13:40:03,163 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_exercise10\".\n",
      "211104-13:40:03,166 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_exercise11\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/exercise1/mapflow/_exercise11\".\n",
      "211104-13:40:03,191 nipype.workflow INFO:\n",
      "\t [Node] Running \"_exercise11\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211104-13:40:03,213 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_exercise11\".\n",
      "211104-13:40:03,215 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_exercise12\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/exercise1/mapflow/_exercise12\".\n",
      "211104-13:40:03,241 nipype.workflow INFO:\n",
      "\t [Node] Running \"_exercise12\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211104-13:40:03,263 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_exercise12\".\n",
      "211104-13:40:03,266 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_exercise13\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/exercise1/mapflow/_exercise13\".\n",
      "211104-13:40:03,292 nipype.workflow INFO:\n",
      "\t [Node] Running \"_exercise13\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211104-13:40:03,316 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_exercise13\".\n",
      "211104-13:40:03,336 nipype.workflow INFO:\n",
      "\t [Node] Finished \"exer_wf.exercise1\".\n",
      "211104-13:40:03,337 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"exer_wf.sum\" in \"/home/neuro/Result/Nipype_tutorial/working_dir/exer_wf/sum\".\n",
      "211104-13:40:03,375 nipype.workflow INFO:\n",
      "\t [Node] Running \"sum\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "211104-13:40:03,399 nipype.workflow INFO:\n",
      "\t [Node] Finished \"exer_wf.sum\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f26b9288d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nipype import Node, Workflow, Function, MapNode\n",
    "\n",
    "exer_node = MapNode(Function(['n'], ['multiply_result'], factorial), iterfield=['n'], name='exercise1')\n",
    "exer_node.inputs.n = [0,1,2,3]\n",
    "\n",
    "sum_node = Node(Function(['fac_list'], ['sum_result'], sum_func), name='sum')\n",
    "\n",
    "ex_wf = Workflow(base_dir='/home/neuro/Result/Nipype_tutorial/working_dir', name='exer_wf')\n",
    "\n",
    "ex_wf.connect([(exer_node, sum_node, [('multiply_result', 'fac_list')])])\n",
    "\n",
    "ex_wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from nipype import Workflow, Node, MapNode, Function\n",
    "import os\n",
    "\n",
    "def range_fun(n_min, n_max):\n",
    "    return list(range(n_min, n_max+1))\n",
    "\n",
    "def factorial(n):\n",
    "    # print(\"FACTORIAL, {}\".format(n))\n",
    "    import math\n",
    "    return math.factorial(n)\n",
    "\n",
    "def summing(terms):\n",
    "    return sum(terms)\n",
    "\n",
    "wf_ex1 = Workflow('ex1')\n",
    "wf_ex1.base_dir = os.getcwd()\n",
    "\n",
    "range_nd = Node(Function(input_names=['n_min', 'n_max'],\n",
    "                         output_names=['range_list'],\n",
    "                         function=range_fun), \n",
    "                name='range_list')\n",
    "\n",
    "factorial_nd = MapNode(Function(input_names=['n'],\n",
    "                                output_names=['fact_out'],\n",
    "                                function=factorial), \n",
    "                       iterfield=['n'],\n",
    "                       name='factorial')\n",
    "\n",
    "summing_nd = Node(Function(input_names=['terms'],\n",
    "                           output_names=['sum_out'],\n",
    "                           function=summing), \n",
    "                  name='summing')\n",
    "\n",
    "\n",
    "range_nd.inputs.n_min = 0\n",
    "range_nd.inputs.n_max = 3\n",
    "\n",
    "wf_ex1.add_nodes([range_nd])\n",
    "wf_ex1.connect(range_nd, 'range_list', factorial_nd, 'n')\n",
    "wf_ex1.connect(factorial_nd, 'fact_out', summing_nd, \"terms\")\n",
    "\n",
    "\n",
    "eg = wf_ex1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "let's print all nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "eg.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "the final result should be 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "list(eg.nodes())[2].result.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "we can also check the results of two other nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "print(list(eg.nodes())[0].result.outputs)\n",
    "print(list(eg.nodes())[1].result.outputs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
